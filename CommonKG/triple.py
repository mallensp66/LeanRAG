import csv
import json
from tools.logger_factory import setup_logger
import re


logger = setup_logger("triple")


class Triple:
    def __init__(self, head, relation, tail):
        self.head = head.strip().replace("<", "").replace(">", "")
        self.relation = relation.strip().replace("<", "").replace(">", "")
        self.tail = tail.strip().replace("<", "").replace(">", "")

    # The `str(Triple)` method can be used to return a triple, which is equivalent to `__str__`.
    def __str__(self):
        return f"<{self.head}>\t<{self.relation}>\t<{self.tail}>"
    @classmethod
    def triple_json_format(self, triple, doc_name="", source_id=""):
        return {"triple": triple, "doc_name": doc_name, "source_id": source_id}

    @classmethod
    def get_example(self, entity, ref_kg_path):
        open_kg = []
        if entity:
            with open(ref_kg_path, "r", encoding="utf-8") as kgfile:
                for line in kgfile:
                    try:
                        triple = Triple(*line.strip().split("\t"))
                        if triple.head.lower() == entity.lower():
                            open_kg.append(str(triple))
                    except:
                        pass

        if open_kg != []:
            logger.info(f"Load open kg triple for {entity} nums: {len(open_kg)}.")
        else:
            open_kg = [
                "<Bacterial sulfate>\t<is a type of>\t<sulfur compound\n",
                "<Diabetes>\t<first line treatment>\t<Metformin>\n",
                "<Insulin>\t<drug type>\t<Long-acting analog>\n",
            ]
            # logger.info(f"use default triples.")
        return open_kg

    ## The triples generated by LLM are processed, and the analysis results are presented.
    @classmethod
    def get_triple(self, entities, res, head_mode="acc"):
        """Obtain triples from the responses of a large model and analyze anomalies."""

        # Save all triples obtained from the LLM output in the form "xx | xx | xx".
        output_triples = set()
        error_triples = set()
        try:
            for item in res.split("\n"):
                item = re.sub(r"^\d+\.\s*", "", item, flags=re.MULTILINE)
                if len(item) > 0:
                    subs = item.split("|")
                    # error format trippleï¼ŒThe format is incorrect and does not conform to "xx | xx | xx".
                    if len(subs) < 3 or len(subs) > 3:
                        continue
                    # Get the head, relation, and tail, create a triplet instance, and add it to output_triples.
                    output_triples.add(Triple(*subs))
        except Exception as e:  # catch all exceptions
            print("The LLM output cannot be parsed into triples:", e)  # Output error message:

        output_triples = list(output_triples)

        for triple in output_triples:
            # acc (Exact Match Mode): This mode requires the head entity of the triple to be exactly the same as the node 
            # (ignoring capitalization and leading and trailing spaces).
            if entities and head_mode == "acc":
                if triple.head.lower() not in [entity.lower() for entity in entities]:
                    error_triples.add(triple)
            elif triple.head.strip() == triple.tail.strip():
                error_triples.add(triple)

        error_triples = list(error_triples)

        ##Remove non-compliant triples
        for triple in error_triples:
            output_triples.remove(triple)

        # Get the tail entity of the newly added triple
        head_entities = set([t.head for t in output_triples])
        tail_entities = set([t.tail for t in output_triples])

        return [str(item) for item in output_triples], head_entities, tail_entities

    @classmethod
    def parse_description_response(self, triple_str:str, response:str):
        """Parse the response and generate a six-tuple string."""
        # Process tab-delimited strings and convert their format.
        parts = triple_str.split('\t')
        cleaned_parts = [part.strip('<').strip('>').strip() for part in parts]  # Remove angle brackets and spaces

        try:
            data = json.loads(response.strip())
            
            # Extract description information
            subject_desc = data.get('subject', {}).get('description', '')
            relation_desc = data.get('relation', {}).get('description', '')
            object_desc = data.get('object', {}).get('description', '')
            
            head, relation, tail = cleaned_parts[0], cleaned_parts[1], cleaned_parts[2]
            
            # Assemble six-tuple format
            return f"<{head}>\t<{subject_desc}>\t<{relation}>\t<{relation_desc}>\t<{tail}>\t<{object_desc}>"
            
        except (json.JSONDecodeError, KeyError) as e:
            logger.error(f"Parse description response failed: {str(e)}, raw response: {response}")
            return triple_str
    @classmethod
    def parse_description_plustype_response(self, triple_str:str, response:str):
        """Parse the response and generate a six-tuple string."""
        # Process tab-delimited strings and convert their format.
        parts = triple_str.split('\t')
        cleaned_parts = [part.strip('<').strip('>').strip() for part in parts]  # Remove angle brackets and spaces
        try:
            data = json.loads(response.strip())
            
            # Extract description information
            subject=data.get('subject', {}).get('name','')
            subject_desc = data.get('subject', {}).get('description', '')
            subject_type = data.get('subject', {}).get('type', '')
            relation = data.get('relation', {}).get('name', '')
            relation_desc = data.get('relation', {}).get('description', '')
            object = data.get('object', {}).get('name', '')
            object_desc = data.get('object', {}).get('description', '')
            object_type = data.get('object', {}).get('type', '')
            
            head, relation, tail = cleaned_parts[0], cleaned_parts[1], cleaned_parts[2]
            
            # Assemble octet format
            return f"<{subject}>\t<{subject_desc}>\t<{subject_type}>\t<{relation}>\t<{relation_desc}>\t<{object}>\t<{object_desc}>\t<{object_type}>"
            
        except (json.JSONDecodeError, KeyError) as e:
            logger.error(f"Parse description response failed: {str(e)}, raw response: {response}")
            return triple_str
